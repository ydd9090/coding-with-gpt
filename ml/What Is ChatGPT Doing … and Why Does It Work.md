# ChatGPT在做什么......以及为什么它能发挥作用？

## 它只是一次添加一个词而已
ChatGPT能够自动生成一些读起来甚至表面上像人类写的文字的东西，这很了不起，也出乎意料。但它是如何做到的呢？为什么它能发挥作用？我在这里的目的是大致介绍一下ChatGPT内部的情况，然后探讨一下为什么它能很好地生成我们认为是有意义的文本。我应该在一开始就说，我将把重点放在正在发生的事情的大画面上，虽然我将提到一些工程细节，但我不会深入研究它们。(我所说的本质也同样适用于目前其他的 "大型语言模型"[LLMs]和ChatGPT。)

首先要解释的是，ChatGPT从根本上说一直在努力做的是对它目前得到的任何文本进行 "合理的延续"，这里的 "合理 "是指 "在看到人们在数十亿个网页上写的东西之后，人们可能期望某人写的东西。"

因此，假设我们已经得到了 "人工智能最好的东西是它的能力 "的文本。想象一下，扫描数十亿页的人类书写的文本（例如在网络上和数字化书籍中），并找到这个文本的所有实例--然后看到什么词在接下来的时间里出现了多少。ChatGPT有效地做了类似的事情，除了（正如我将解释的）它不看字面文本；它寻找在某种意义上 "意义相符 "的东西。但最终的结果是，它产生了一个可能紧随其后的词的排序列表，以及 "概率"：

值得注意的是，当ChatGPT做一些事情，比如写一篇文章时，它所做的基本上只是一遍又一遍地问："鉴于目前的文本，下一个词应该是什么？"--每次都会添加一个词。(更准确地说，正如我将解释的那样，它在添加一个 "标记"，这可能只是一个词的一部分，这就是为什么它有时可以 "编造新词 "的原因）。

但是，好吧，在每一步，它得到一个带有概率的单词列表。但是，它究竟应该选择哪一个来添加到它正在写的文章（或其他什么）中呢？人们可能认为它应该是 "排名最高 "的词（即被分配到最高 "概率 "的那个）。但是，这时就会有一点巫术开始悄悄出现。因为出于某种原因--也许有一天我们会有一个科学式的理解--如果我们总是挑选排名最高的词，我们通常会得到一篇非常 "平淡 "的文章，似乎从来没有 "显示出任何创造力"（甚至有时一字不差地重复）。但是，如果我们有时（随机地）挑选排名较低的词，我们会得到一篇 "更有趣 "的文章。

这里有随机性的事实意味着，如果我们多次使用同一个提示，我们很可能每次都得到不同的作文。而且，为了与巫术的想法保持一致，有一个特定的所谓 "温度 "参数，它决定了多长时间会使用排名较低的词，而对于论文的生成，事实证明，0.8的 "温度 "似乎是最好的。(值得强调的是，这里没有使用任何 "理论"；这只是一个在实践中被发现可行的问题）。例如，"温度 "的概念之所以存在，是因为恰好使用了统计物理学中熟悉的指数分布，但没有 "物理 "联系--至少到目前为止我们知道。）

在我们继续之前，我应该解释一下，为了论述的目的，我大多不会使用ChatGPT中的完整系统；相反，我通常会使用更简单的GPT-2系统，它有一个很好的特点，即它足够小，可以在标准的台式电脑上运行。因此，对于我展示的所有内容，我将能够包括明确的沃尔弗拉姆语言代码，你可以立即在你的计算机上运行。(点击这里的任何图片可以复制它背后的代码)。

例如，这里是如何获得上述概率表的。首先，我们必须检索底层的 "语言模型 "神经网络：

稍后，我们将看看这个神经网的内部，并谈谈它是如何工作的。但现在我们可以把这个 "网络模型 "作为一个黑匣子应用到我们迄今为止的文本中，并要求按概率计算出模型说应该遵循的前5个词：

这就把这个结果变成了一个明确的格式化的 "数据集"：

下面是如果重复 "应用模型 "的情况--在每一步中加入概率最高的词（在此代码中被指定为模型中的 "决定"）：

如果再继续下去会怎样？在这种（"零温度"）情况下，很快就会出现相当混乱和重复的情况：

但如果不总是挑选 "顶级 "词，而是有时随机挑选 "非顶级 "词（"随机性 "对应 "温度 "为0.8）呢？人们又可以建立起文本：

而每次这样做，都会有不同的随机选择，文本也会不同--如这5个例子：

值得指出的是，即使在第一步，也有很多可能的 "下一个词 "可供选择（温度为0.8），尽管它们的概率下降得相当快（而且，是的，这个对数图上的直线对应于n-1的 "幂律 "衰减，这是语言的一般统计中非常有特点的）：

那么，如果一个人的时间更长，会发生什么？这里有一个随机的例子。它比顶部的词（零温度）的情况要好，但充其量还是有点奇怪：

这是用最简单的GPT-2模型（来自2019年）完成的。使用较新和较大的GPT-3模型，结果更好。下面是用同样的 "提示 "产生的顶字（零温度）文本，但用最大的GPT-3模型：

这里有一个在 "温度0.8 "的随机例子：

概率是怎么来的？
好吧，ChatGPT总是根据概率来选择下一个词。但这些概率从何而来？让我们从一个更简单的问题开始。让我们考虑一次生成一个字母（而不是单词）的英语文本。我们怎样才能算出每个字母的概率呢？

我们可以做的一个非常简单的事情就是取一个英语文本的样本，然后计算不同字母在其中出现的频率。因此，举例来说，我们可以计算维基百科上关于 "猫 "的文章中的字母。

而这对 "狗 "也有同样的作用：

结果是相似的，但不一样（"o "在 "dogs "文章中无疑更常见，因为毕竟它出现在 "dog "这个词本身）。尽管如此，如果我们采取足够大的英语文本样本，我们可以期待最终得到至少是相当一致的结果：

下面是一个样本，如果我们只是用这些概率生成一个字母序列，我们会得到什么：


我们可以通过添加空格将其分解成 "单词"，就像它们是具有一定概率的字母一样：


我们可以通过强迫 "字长 "的分布与英语中的分布相一致，在制作 "单词 "方面做得稍微好一点：


我们在这里没有碰巧得到任何 "实际的单词"，但结果看起来稍好一些。不过，要想更进一步，我们需要做的不仅仅是随机地分别挑选每个字母。而且，例如，我们知道，如果我们有一个 "q"，下一个字母基本上必须是 "u"。

这里有一个字母本身的概率图：

这里有一个图，显示了典型英语文本中成对的字母（"2-grams"）的概率。可能的第一个字母显示在页面上，第二个字母显示在页面下：

例如，我们在这里看到，除了 "u "行，"q "列是空白的（概率为零）。好了，现在我们不再是一次生成一个字母的 "单词"，而是一次生成两个字母，使用这些 "2-gram "概率。下面是一个结果的样本--其中恰好包括一些 "实际的词"：


有了足够多的英语文本，我们不仅可以对单个字母或成对字母（2-grams）的概率进行很好的估计，而且还可以对较长的字母进行估计。如果我们用逐渐变长的n-gram概率生成 "随机词"，我们就会发现它们逐渐变得 "更现实"：

但现在让我们假设--或多或少像ChatGPT那样--我们是在处理整个单词，而不是字母。英语中大约有40,000个合理的常用词。通过查看一个大型的英语文本语料库（比如几百万本书，总共有几千亿个单词），我们可以得到每个单词的常用程度的估计。利用这一点，我们可以开始生成 "句子"，其中每个词都是独立随机抽取的，其出现的概率与语料库中的相同。下面是我们得到的一个样本：

毫不奇怪，这是无稽之谈。那么，我们如何才能做得更好呢？就像对待字母一样，我们可以开始考虑的不仅仅是单个词的概率，还有成对的或更长的词的n-grams的概率。在成对的情况下，以下是我们得到的5个例子，所有情况都是从 "猫 "这个词开始的：
```wolfram
Cell[ CellGroupData[{Cell[BoxData[ RowBox[{ RowBox[{"SeedRandom", "[", "2134", "]"}], ";", RowBox[{"StringJoin", "[", RowBox[{"Riffle", "[", RowBox[{ RowBox[{"Table", "[", "\[IndentingNewLine]", RowBox[{ RowBox[{ InterpretationBox[ TagBox[ FrameBox[ PaneBox[GridBox[{ { StyleBox[ StyleBox[ AdjustmentBox["\<\"[\[FilledSmallSquare]]\"\>", BoxBaselineShift->-0.25, BoxMargins->{{0, 0}, {-1, -1}}], "ResourceFunctionIcon", FontColor->GrayLevel[0.45]], ShowStringCharacters->False, FontFamily->"Source Sans Pro Black", FontSize->0.65 Inherited, FontWeight->"Heavy", PrivateFontOptions->{"OperatorSubstitution"->False}], StyleBox[ RowBox[{ StyleBox["\<\"WeightedRandomWord\"\>", "ResourceFunctionLabel"], " "}], ShowAutoStyles->False, ShowStringCharacters->False, FontSize->0.9 Inherited, FontColor->GrayLevel[0.1]]} }, GridBoxSpacings->{"Columns" -> {{0.25}}}], Alignment->Left, BaseStyle->{LineSpacing -> {0, 0}, LineBreakWithin -> False}, BaselinePosition->Baseline, FrameMargins->{{3, 0}, {0, 0}}], Background->RGBColor[0.968627, 0.976471, 0.984314], BaselinePosition->Baseline, DefaultBaseStyle->{}, FrameMargins->{{0, 0}, {1, 1}}, FrameStyle->RGBColor[0.831373, 0.847059, 0.85098], RoundingRadius->4], {"FunctionResourceBox", GrayLevel[0.45], "\"WeightedRandomWord\""}, TagBoxNote->"FunctionResourceBox"], ResourceFunction[ ResourceObject[<| "Name" -> "WeightedRandomWord", "UUID" -> "8b65adbe-9127-4efa-b7a5-596d9ebdbb17", "ResourceType" -> "Function", "ResourceLocations" -> { CloudObject[ "https://www.wolframcloud.com/obj/sw-writings0/Resources/8b6/\ 8b65adbe-9127-4efa-b7a5-596d9ebdbb17"]}, "Version" -> None, "DocumentationLink" -> URL["https://www.wolframcloud.com/obj/sw-writings0/ChatTech/\ WeightedRandomWord"], "ExampleNotebookData" -> Automatic, "FunctionLocation" -> CloudObject[ "https://www.wolframcloud.com/obj/sw-writings0/Resources/8b6/\ 8b65adbe-9127-4efa-b7a5-596d9ebdbb17/download/DefinitionData"], "ShortName" -> "WeightedRandomWord", "SymbolName" -> "FunctionRepository`$8b65adbe91274efab7a5596d9ebdbb17`\ WeightedRandomWord"|>]], Selectable->False], "[", "]"}], ",", "\[IndentingNewLine]", RowBox[{"{", "30", "}"}]}], "]"}], ",", "\"\< \>\""}], "]"}], "]"}]}]], "Input", CellChangeTimes->{{3.883608570272408*^9, 3.883608570458043*^9}, { 3.8836129678718367`*^9, 3.883613004941204*^9}, 3.885345792241777*^9}, CellLabel->"In[22]:=", CellID->1088523936] }, Open] ]
```

它正在变得稍微 "看起来很合理"。我们可以想象，如果我们能够使用足够长的n-grams，我们基本上会 "得到一个ChatGPT"--在这个意义上，我们会得到一些东西，可以生成具有 "正确的整体论文概率 "的论文长度的单词序列。但问题是：从来没有足够的英语文本能够推导出这些概率。

在网络的抓取中，可能有几千亿个单词；在已经数字化的书籍中，可能有另外几千亿个单词。但是有了4万个常用词，即使是可能的2-grams的数量也已经是16亿了，可能的3-grams的数量是60万亿。所以我们没有办法从现有的文本中估计出所有这些的概率。而当我们达到20个字的 "文章片段 "时，可能性的数量比宇宙中的粒子数量还要多，所以从某种意义上说，它们永远不可能全部被写下来。

那么我们能做什么呢？最大的想法是建立一个模型，让我们估计序列出现的概率--即使我们在所看的文本语料库中从未明确见过这些序列。而ChatGPT的核心正是一个所谓的 "大型语言模型"（LLM），它的建立可以很好地估计这些概率。

## 什么是模型？
假设你想知道（就像伽利略在15世纪末所做的那样），从比萨塔的每一层落下的炮弹需要多长时间才能落地。那么，你可以在每一种情况下测量它，并将结果制成表格。或者你可以做理论科学的精髓：建立一个模型，给出某种计算答案的程序，而不是仅仅测量和记住每个案例。

让我们想象一下，我们有（有点理想化的）数据，说明炮弹从不同楼层落下需要多长时间：

```wolfram
Cell[ CellGroupData[{Cell[BoxData[ RowBox[{ RowBox[{"SeedRandom", "[", "34535", "]"}], ";", RowBox[{"ListPlot", "[", RowBox[{ RowBox[{ RowBox[{ RowBox[{"{", RowBox[{"#", ",", RowBox[{"Sqrt", "[", "#", "]"}]}], "}"}], "&"}], "/@", RowBox[{"Sort", "[", "\[IndentingNewLine]", RowBox[{"RandomSample", "[", RowBox[{ RowBox[{"Range", "[", "50", "]"}], ",", "20"}], "]"}], "]"}]}], ",", RowBox[{"Frame", "->", "True"}], ",", RowBox[{"PlotRange", "->", RowBox[{"{", RowBox[{"0", ",", RowBox[{"Sqrt", "[", "50", "]"}]}], "}"}]}], ",", "\[IndentingNewLine]", RowBox[{"PlotStyle", "->", RowBox[{"{", RowBox[{ RowBox[{ RowBox[{ InterpretationBox[ TagBox[ FrameBox[ PaneBox[GridBox[{ { StyleBox[ StyleBox[ AdjustmentBox["\<\"[\[FilledSmallSquare]]\"\>", BoxBaselineShift->-0.25, BoxMargins->{{0, 0}, {-1, -1}}], "ResourceFunctionIcon", FontColor->GrayLevel[0.45]], ShowStringCharacters->False, FontFamily->"Source Sans Pro Black", FontSize->0.65 Inherited, FontWeight->"Heavy", PrivateFontOptions->{"OperatorSubstitution"->False}], StyleBox[ RowBox[{ StyleBox["\<\"ChatTechColors\"\>", "ResourceFunctionLabel"], " "}], ShowAutoStyles->False, ShowStringCharacters->False, FontSize->0.9 Inherited, FontColor->GrayLevel[0.1]]} }, GridBoxSpacings->{"Columns" -> {{0.25}}}], Alignment->Left, BaseStyle->{LineSpacing -> {0, 0}, LineBreakWithin -> False}, BaselinePosition->Baseline, FrameMargins->{{3, 0}, {0, 0}}], Background->RGBColor[0.968627, 0.976471, 0.984314], BaselinePosition->Baseline, DefaultBaseStyle->{}, FrameMargins->{{0, 0}, {1, 1}}, FrameStyle->RGBColor[0.831373, 0.847059, 0.85098], RoundingRadius->4], {"FunctionResourceBox", GrayLevel[0.45], "\"ChatTechColors\""}, TagBoxNote->"FunctionResourceBox"], ResourceFunction[ ResourceObject[<| "Name" -> "ChatTechColors", "UUID" -> "e94a8649-0716-452b-8a07-06cee4cfd4e3", "ResourceType" -> "Function", "ResourceLocations" -> { CloudObject[ "https://www.wolframcloud.com/obj/sw-writings0/Resources/e94/\ e94a8649-0716-452b-8a07-06cee4cfd4e3"]}, "Version" -> None, "DocumentationLink" -> URL["https://www.wolframcloud.com/obj/sw-writings0/ChatTech/\ ChatTechColors"], "ExampleNotebookData" -> Automatic, "FunctionLocation" -> CloudObject[ "https://www.wolframcloud.com/obj/sw-writings0/Resources/e94/\ e94a8649-0716-452b-8a07-06cee4cfd4e3/download/DefinitionData"], "ShortName" -> "ChatTechColors", "SymbolName" -> "FunctionRepository`$e94a86490716452b8a0706cee4cfd4e3`\ ChatTechColors"|>]], Selectable->False], "[", "\"\\"", "]"}], "[", "\"\\"", "]"}], ",", "\[IndentingNewLine]", RowBox[{"PointSize", "[", ".015", "]"}]}], "}"}]}], ",", RowBox[{"AspectRatio", "->", RowBox[{"1", "/", "2"}]}]}], "]"}]}]], "Input", CellChangeTimes->{{3.883615954551203*^9, 3.883616084284227*^9}, { 3.883616115619169*^9, 3.8836161223055353`*^9}, {3.88361615400772*^9, 3.883616196812332*^9}, 3.884688242572605*^9, 3.885345880315859*^9}, CellLabel->"", CellID->749798475] }, Open] ]
```

我们如何计算出从一个我们没有明确数据的楼层坠落需要多长时间？在这种特殊情况下，我们可以用已知的物理学定律来计算。但是，如果说我们所得到的只是数据，而我们不知道有什么基本定律在支配它。那么我们就可以做一个数学上的猜测，比如说，也许我们应该用一条直线作为模型：

我们可以选择不同的直线。但这是平均来说最接近我们所得到的数据的一条。根据这条直线，我们可以估计出任何楼层的下降时间。

我们怎么知道要在这里尝试使用一条直线呢？在某种程度上，我们并不知道。这只是数学上简单的东西，而我们已经习惯了这样的事实：我们测量的很多数据都被数学上简单的东西很好地拟合。我们可以尝试一些数学上更复杂的东西--比如说a+b x+c x2--然后在这种情况下我们做得更好：

不过，事情可能会出大错。比如这里是我们对a+b/x+c sin(x)所能做的最好结果：

值得理解的是，从来没有一个 "无模型的模型"。你使用的任何模型都有一些特定的基础结构，然后有一组 "你可以转动的旋钮"（即你可以设置的参数）来适应你的数据。而在ChatGPT的案例中，使用了很多这样的 "旋钮"--实际上，有1750亿个。

但令人瞩目的是，ChatGPT的基本结构--"仅仅 "有这么多的参数--足以使一个计算下一个单词概率的模型 "足够好"，从而为我们提供合理的文章长度的文本。

类似人类任务的模型
我们在上面举的例子涉及到为数字数据建立模型，这些数据基本上来自于简单的物理学--几个世纪以来我们都知道 "简单数学适用"。但是对于ChatGPT，我们必须为人类语言文本建立一个模型，即由人脑产生的那种模型。而对于这样的东西，我们（至少现在）还没有类似 "简单数学 "的东西。那么，它的模型可能是什么样的呢？

在我们谈论语言之前，让我们先谈谈另一项类似人类的任务：识别图像。而作为一个简单的例子，让我们考虑数字的图像（是的，这是一个经典的机器学习例子）：

我们可以做的一件事是为每个数字获取一堆样本图像：

那么，要想知道作为输入的图像是否对应于某个特定的数字，我们只需与我们拥有的样本进行明确的逐个像素的比较。但作为人类，我们似乎可以做得更好--因为我们仍然可以识别数字，即使它们是手写的，并且有各种各样的修改和扭曲：

当我们为上面的数字数据建立一个模型时，我们能够取一个给定的数字值x，然后为特定的a和b计算a+b x。因此，如果我们把这里的每个像素的灰度值当作某个变量xi，是否有一些所有这些变量的函数，当被评估时，告诉我们图像是什么数字？事实证明，有可能构建这样一个函数。不足为奇的是，它并不特别简单。一个典型的例子可能涉及50万次数学运算。

但最终的结果是，如果我们把一幅图像的像素值集合输入这个函数，就会得出一个数字，指定我们的图像是哪个数字。稍后，我们将讨论如何构建这样一个函数，以及神经网络的概念。但现在让我们把这个函数当作黑匣子，我们把手写数字的图像（作为像素值的数组）输入其中，然后得到这些数字所对应的数字：

但这里到底发生了什么？假设我们逐渐模糊了一个数字。有一段时间，我们的函数仍然 "识别 "它，在这里是一个 "2"。但很快它就 "失去 "了，并开始给出 "错误 "的结果：

但为什么我们说这是 "错误 "的结果？在这种情况下，我们知道我们通过模糊一个 "2 "得到了所有的图像。但是，如果我们的目标是制作一个人类识别图像的模型，那么真正要问的问题是，如果遇到这些模糊的图像之一，而又不知道它来自哪里，人类会怎么做。

如果我们从我们的功能中得到的结果通常与人类会说的话一致，我们就有一个 "好的模型"。而非微不足道的科学事实是，对于像这样的图像识别任务，我们现在基本上知道如何构建这样的函数。

我们能 "从数学上证明 "它们的作用吗？嗯，不能。因为要做到这一点，我们必须有一个关于我们人类正在做什么的数学理论。以 "2 "图像为例，改变几个像素。我们可以想象，只有几个像素 "不合适"，我们还是应该认为这个图像是 "2"。但这应该到什么程度呢？这是一个关于人类视觉感知的问题。而且，是的，对于蜜蜂或章鱼来说，答案无疑是不同的--对于假定的外星人来说，可能完全不同。

## 神经网络
好吧，那么我们的典型模型对于像图像识别这样的任务究竟是如何工作的呢？目前最流行、最成功的方法是使用神经网络。在20世纪40年代，神经网络的发明形式与今天的使用非常接近，它可以被认为是对大脑似乎如何工作的简单理想化。

在人类的大脑中，有大约1000亿个神经元（神经细胞），每个神经元都能产生电脉冲，每秒可能有一千次。这些神经元在一个复杂的网络中连接起来，每个神经元都有树状的分支，允许它将电信号传递给也许成千上万的其他神经元。粗略估计，任何给定的神经元是否在某一时刻产生电脉冲，取决于它从其他神经元收到的脉冲--不同的连接有不同的 "权重"。

当我们 "看到一个图像 "时，所发生的事情是，当来自图像的光子落在我们眼睛后面的（"光感受器"）细胞上时，它们在神经细胞中产生电信号。这些神经细胞与其他神经细胞相连，最终信号通过一整层的神经元。正是在这个过程中，我们 "识别 "了图像，最终 "形成了一个想法"，即我们 "看到了一个2"（也许最后会做一些事情，如大声说出 "2 "这个词）。

上一节中的 "黑盒子 "函数是这样一个神经网络的 "数学化 "版本。它刚好有11层（虽然只有4个 "核心层"）：

关于这个神经网络，没有什么特别的 "理论推导"；它只是在1998年作为一项工程被建造出来的东西，并且被发现可以工作。(当然，这与我们描述我们的大脑是通过生物进化过程产生的没有什么不同）。

好吧，但是像这样的神经网络是如何 "识别事物 "的？关键在于吸引器的概念。想象一下，我们有手写的1和2的图像：

我们希望所有的1都 "被吸引到一个地方"，而所有的2都 "被吸引到另一个地方"。或者，换一种方式，如果一个图像在某种程度上 "更接近于1 "而不是2，我们希望它最终出现在 "1的地方"，反之亦然。

作为一个直接的类比，我们假设在平面上有某些位置，用点表示（在现实生活中，它们可能是咖啡店的位置）。那么我们可以想象，从平面上的任何一点开始，我们总是想在最近的点结束（即我们总是去最近的咖啡店）。我们可以通过将平面划分为由理想化的 "分水岭 "分隔的区域（"吸引盆地"）来表示这一点：

